---
apiVersion: ollama.ayaka.io/v1
kind: Model
metadata:
  name: qwen3-4b
spec:
  # Model image
  image: qwen3:4b

  # GPU scheduling
  runtimeClassName: nvidia

  # Storage configuration
  storageClassName: openebs-hostpath

  # Resource limits - strict to force GPU memory usage
  resources:
    limits:
      nvidia.com/gpu: "1"
      memory: 2Gi
    requests:
      cpu: 100m
      memory: 512Mi

  # Ollama runtime parameters
  env:
    - name: OLLAMA_KEEP_ALIVE
      value: "24h"
    - name: OLLAMA_LOAD_TIMEOUT
      value: "600"
    - name: OLLAMA_NUM_CTX
      value: "4096"
    - name: OLLAMA_HOST
      value: "0.0.0.0"
    - name: OLLAMA_ORIGINS
      value: "*"
